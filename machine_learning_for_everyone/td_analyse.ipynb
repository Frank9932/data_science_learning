{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de503d29",
   "metadata": {},
   "source": [
    "###### https://www.youtube.com/watch?v=i_LwzRVP7bg&list=PLWKjhJtqVAblStefaz_YOVpDWqcRScc2s&index=1\n",
    "###### https://colab.research.google.com/drive/1m3oQ9b0oYOT-DXEy0JCdgWPLGllHMb4V?usp=sharing#scrollTo=17bmL-NpKUhE\n",
    "###### https://colab.research.google.com/drive/16w3TDn_tAku17mum98EWTmjaLHAJcsk0?usp=sharing#scrollTo=-Vohv6aAzZFK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01c6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ! pip install scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# ! pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556577e",
   "metadata": {},
   "source": [
    "## data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fea4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df=pd.read_csv(\"magic04.data\",names=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119445ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4fb7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95337d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in cols[:-1]:\n",
    "  plt.hist(df[df[\"class\"]==1][label], color='blue', label='gamma', alpha=0.7, density=True) # density=True for normalize data\n",
    "  plt.hist(df[df[\"class\"]==0][label], color='red', label='hadron', alpha=0.7, density=True)\n",
    "  plt.title(label)\n",
    "  plt.ylabel(\"Probability\")\n",
    "  plt.xlabel(label)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6132221",
   "metadata": {},
   "source": [
    "### Train, validation, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e2808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the DataFrame and split it into training (60%), validation (20%), and test sets (20%)\n",
    "# random_state=42 ensures reproducibility, so the shuffling is the same every time you run the code\n",
    "train, valid, test = np.split(df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c38b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[train['class']==1]), len(train[train['class']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ce1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe, oversample=False):\n",
    "    x = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "\n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        x, y = ros.fit_resample(x, y)\n",
    "        \n",
    "    data = np.hstack((x, np.reshape(y, (-1, 1))))\n",
    "    return data, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8781cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, x_train, y_train = scale_dataset(train, oversample=True)\n",
    "valid, x_valid, y_valid = scale_dataset(valid, oversample=False)\n",
    "test, x_test, y_test = scale_dataset(test, oversample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdd2ea",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f48da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d645c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87911851",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342215a1",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab9ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c1352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b23e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a26ab0",
   "metadata": {},
   "source": [
    "# Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e871960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41bf3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693ec65",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fefbfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9574c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c044bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4424b",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a96a1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02bd6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e99b6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "  ax1.plot(history.history['loss'], label='loss')\n",
    "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.set_ylabel('Binary crossentropy')\n",
    "  ax1.grid(True)\n",
    "\n",
    "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
    "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.grid(True)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0824ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "  nn_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(10,)),\n",
    "      tf.keras.layers.Dropout(dropout_prob),\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "      tf.keras.layers.Dropout(dropout_prob),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  history = nn_model.fit(\n",
    "    X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0\n",
    "  )\n",
    "\n",
    "  return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "epochs=100\n",
    "for num_nodes in [16, 32, 64]:\n",
    "  for dropout_prob in[0, 0.2]:\n",
    "    for lr in [0.01, 0.005, 0.001]:\n",
    "      for batch_size in [32, 64, 128]:\n",
    "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size}\")\n",
    "        model, history = train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
    "        plot_history(history)\n",
    "        val_loss = model.evaluate(x_valid, y_valid)[0]\n",
    "        if val_loss < least_val_loss:\n",
    "          least_val_loss = val_loss\n",
    "          least_loss_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a542e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = least_loss_model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
